# Module-5-Content-Based-Image-Retrieval


1.視覺詞彙模型概念

  -將圖像表示為無序的圖像塊集合
  
  -一張圖像會擁有好幾個不同區塊 : 例如一張人臉，會有眼睛、鼻子、嘴巴等等
  
  -我們可以透過影像描述相關演算法，萃取出每個區塊圖像對應的特徵向量
  
  -假設同時擁有(人臉(眼睛、鼻子、嘴巴)、腳踏車(輪子、車身、齒輪)、馬克杯(手把、圓弧杯身))，所有的區塊特徵向量都會被無序的蒐集再一個大型的圖塊袋內
  
  -當我們輸入一張人臉，經過分析區塊特徵分析，展示出一個與大型圖塊袋比較的直方圖(輸入影像的分散圖塊與大型圖塊雷同出現次數直方圖)，可以發現鼻子、眼睛等出現次數遠大過其他圖塊雷同的次數，透過這種方式可以辨識出其為人臉
  
2.實際應用 : 
  
  1.圖像區塊特徵提取(透過keypoint萃取其周圍影像描述(SIFT,SURF..))，並使用HDF5儲存.hdf5檔
  
    -hdf5資料庫
      
      -image_ids : 儲存影像標號
    
      -index : 儲存每張圖像特徵向量index起始於結束位置
      
      -features : 圖像萃取出來的特徵向量

  2.產生視覺單詞(影像的視覺單詞其實就是把所有特徵向量拋入，透過聚類分出不同的群，每一群都是一個視覺單詞)
  
    -MiniBatchKMeans : 使用K-Means分群，每一群都可視作一個視覺單詞

    -分成64個集群(64個視覺單詞)

  3.查看視覺單詞在圖像中的樣貌
    
    -將所有的圖像集產出的(關鍵點以及其搭配的局部影像描述)去針對64個分群產出的特徵向量進行歐基里德距離計算
    
    -因此64個分群每一個都有與所有關檢點之局部影像產出一個相似度的值
    
    -透過關鍵點的位置，擷取對應影像居部區域
  
  4.實際建構CBIR系統
    
    -前三個步驟主要可以透過萃取影像關鍵點與局部影像描述，產出一張影像同時擁有多組的特徵向量
    
    -前三個步驟後經過K-Means聚合亦會產出我們設定的64個視覺單詞分群
    
    -我們目前擁有的資料包含:
      
      1).儲存所有影像產出的特徵向量資料庫
      
      2).64個分群的特徵向量資料庫
      
    -接著我們可以把每一張影像對應的特徵向量集假設200筆拿去與64個分群的特徵向量計算其歐基里德距離
    
    -因此每一筆特徵向量一定會與64筆分群特徵向量中其中一筆距離最近，我們則給予那筆分群特徵向量+1
    
    -經過上述過程，我們就可以得到一個直方圖陣列(維度為64)，將所有加總剛好會是200
    
    -而此過程正是每一張影像透過CBIR系統可以產出最後精簡的特徵向量的過程
  

